#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Jan 22 10:11:00 2022

@author: usr
"""
import os, sys
import time
import random
import numpy as np
import copy
import numpy as np
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import RandomForestRegressor
from scipy.stats import norm
import math
from sklearn.ensemble import RandomForestRegressor
#random.seed(456)
iters = 60
begin2end = 5
md = int(os.environ.get('MODEL', 1))
fnum = int(os.environ.get('FNUM', 8))
decay = float(os.environ.get('DECAY', 0.5))
scale = float(os.environ.get('SCALE', 10))
offset = float(os.environ.get('OFFSET', 20))

cmd2 = ' -I ../polybench/utilities -I ../polybench/linear-algebra/kernels/2mm ../polybench/utilities/polybench.c ../polybench/linear-algebra/kernels/2mm/2mm.c -lm -DPOLYBENCH_TIME -o 2mm_time'
cmd3 = 'gcc -O2 -funswitch-loops -ftree-vectorize -fpredictive-commoning -fipa-cp-clone -finline-functions -fgcse-after-reload -I ../polybench/utilities -I ../polybench/linear-algebra/kernels/2mm ../polybench/utilities/polybench.c ../polybench/linear-algebra/kernels/2mm/2mm.c -lm -DPOLYBENCH_TIME -o 2mm_time'
cmd4 = 'rm -rf *.o *.I *.s a.out'
cmd5 = './2mm_time'
                                                                   
#大的搜索空间
#options = ['-fno-peephole2', '-ffast-math', '-fno-schedule-insns2', '-fno-caller-saves', '-funroll-all-loops', '-fno-inline-small-functions', '-finline-functions', '-fno-math-errno', '-fno-tree-pre', '-ftracer', '-fno-reorder-functions', '-fno-dce', '-fipa-cp-clone', '-fno-move-loop-invariants', '-fno-regmove', '-funsafe-math-optimizations', '-fno-tree-loop-optimize', '-fno-merge-constants', '-fno-omit-frame-pointer', '-fno-align-labels', '-fno-tree-ter', '-fno-tree-dse', '-fwrapv', '-fgcse-after-reload', '-fno-align-jumps', '-fno-asynchronous-unwind-tables', '-fno-cse-follow-jumps', '-fno-ivopts', '-fno-guess-branch-probability', '-fprefetch-loop-arrays', '-fno-tree-coalesce-vars', '-fno-common', '-fpredictive-commoning', '-fno-unit-at-a-time', '-fno-cprop-registers', ' ', '-fno-early-inlining', '-fno-delete-null-pointer-checks', '-fselective-scheduling2', '-fno-gcse', '-fno-inline-functions-called-once', '-funswitch-loops', '-fno-tree-vrp', '-fno-tree-dce', '-fno-jump-tables', '-ftree-vectorize', '-fno-argument-alias', '-fno-schedule-insns', '-fno-branch-count-reg', '-fno-tree-switch-conversion', '-fno-auto-inc-dec', '-fno-crossjumping', '-fno-tree-fre', '-fno-tree-reassoc', '-fno-align-functions', '-fno-defer-pop', '-fno-optimize-register-move', '-fno-strict-aliasing', '-fno-rerun-cse-after-loop', '-fno-tree-ccp', '-fno-ipa-cp', '-fno-if-conversion2', '-fno-tree-sra', '-fno-expensive-optimizations', '-fno-tree-copyrename', '-fno-ipa-reference', '-fno-ipa-pure-const', '-fno-thread-jumps', '-fno-if-conversion', '-fno-reorder-blocks', '-falign-loops']

#约简的搜索空间
options=['-fno-peephole2', '-ffast-math', '-fno-schedule-insns2', '-fno-caller-saves', '-funroll-all-loops', '-fno-inline-small-functions', '-finline-functions', '-fno-tree-pre', '-ftracer', '-fno-reorder-functions', '-fno-dce', '-fno-move-loop-invariants', '-funsafe-math-optimizations', '-fno-tree-loop-optimize', '-fno-merge-constants', '-fno-omit-frame-pointer', '-fno-tree-ter', '-fwrapv', '-fgcse-after-reload', '-fno-align-jumps', '-fno-asynchronous-unwind-tables', '-fno-cse-follow-jumps', '-fno-ivopts', '-fno-guess-branch-probability', '-fprefetch-loop-arrays', '-fno-tree-coalesce-vars', '-fno-common', '-fpredictive-commoning', '-fno-unit-at-a-time', '-fno-cprop-registers', '-fselective-scheduling2', '-fno-gcse', '-fno-inline-functions-called-once', '-funswitch-loops', '-fno-tree-vrp', '-fno-tree-dce', '-ftree-vectorize', '-fno-crossjumping', '-fno-tree-fre', '-fno-tree-reassoc', '-fno-align-functions', '-fno-rerun-cse-after-loop', '-fno-tree-ccp', '-fno-ipa-cp', '-fno-if-conversion2', '-fno-expensive-optimizations', '-fno-ipa-pure-const', '-fno-if-conversion']

def generate_opts(independent):
    result = []
    for k, s in enumerate(independent):
        if s == 1:
            result.append(options[k])
    independent = result

    return independent

def get_objective_score(independent):
    independent = generate_opts(independent)
    
    speedups = []
    step = 0
    while (len(speedups) < 6):
        step += 1
        if step > 10:
            print('failed configuration!')
            sys.exit(0)
        os.system(cmd4)
        print('gcc -O2 ' + ' '.join(independent) + cmd2)
        os.system('gcc -O2 ' + ' '.join(independent) + cmd2)
        
        begin = time.time()
        print(cmd5)
        ret = os.system(cmd5)
        if ret != 0:
            continue
        print(ret)
        end = time.time()
        de = end - begin
        #*******************
        #de表示编译序列优化后所需的时间
        #********************
        os.system(cmd4)
        os.system(cmd3)

        begin = time.time()
        os.system(cmd5)
        end = time.time()
        nu = end - begin
        #***********************
        #nu 表示O2所需要的运行时间
        #***********************
        print('nu:' + str(nu) + ' de:' + str(de) + ' val:' + str(nu / de))
        speedups.append(nu / de)
        #speedup指的是o2/seq，这个值越大表示seq优化效果越好 
    print(speedups)
    #返回的取平均值，且加了负号，这表示值都为负数，其值越小表示seq优化效果越好
    return -np.median(speedups)
    
def generate_conf(x):
    comb = bin(x).replace('0b', '')
    comb = '0' * (len(options) - len(comb)) + comb
    conf = []
    for k, s in enumerate(comb):
        if s == '1':
            conf.append(1)
        else:
            conf.append(0)
    return conf


def get_median(data):
    temp_data=[]
    for i in data:
        temp_data.append(i)
    temp_data = sorted(temp_data)
    size = len(temp_data)
    if size % 2 == 0: # 判断列表长度为偶数
        median = (temp_data[size//2]+temp_data[size//2-1])/2
        temp_data[0] = median
    if size % 2 == 1: # 判断列表长度为奇数
        median = temp_data[(size-1)//2]
        temp_data[0] = median
    return temp_data[0]

def variation_x(x):
    temp_x=[]
    for i in x:
        temp_x.append(i)
    var_loc=random.randrange(len(x))
    if(temp_x[var_loc]==0):
        temp_x[var_loc]=1
    else:
        temp_x[var_loc]=0
    return temp_x
def cross_x1_x2(x1,x2):
    temp_x1=[]
    for i in x1:
        temp_x1.append(i)
    temp_x2=[]
    for i in x2:
        temp_x2.append(i)
    start_loca = random.randrange(len(x1)-1)
    end_loca = random.randrange(len(x1)-start_loca)+start_loca

    for i in range(end_loca-start_loca):
        temp=temp_x1[start_loca+i]
        temp_x1[start_loca+i]=temp_x2[start_loca+i]
        temp_x2[start_loca+i]=temp
    return temp_x1,temp_x2



def get_bets_list(training_indep,training_dep):
    temp_indep=[]
    temp_dep=[]
    
    ret_indep=[]
    ret_dep=[]
    for i in training_indep:
        temp_indep.append(i)
    for i in training_dep:
        temp_dep.append(i)
    sorted_indices = np.argsort(temp_dep, axis=0)
    
    #返回的是前十的个体
    for i in range(10):
        ret_indep.append(temp_indep[sorted_indices[i]])
        ret_dep.append(temp_dep[sorted_indices[i]])
    
    return ret_indep,ret_dep

#运行hlg 第二阶段的算法
if __name__ == '__main__':
    print("****************start********************")
    best_result=[]
    a=time.time()
    training_indep = []

    initial_sample_size = 30
    # initial_sample_size 第一代种群中的个体数
    while len(training_indep) < initial_sample_size:
        x = random.randint(0, 2 ** len(options))
        x = generate_conf(x)
        if x not in training_indep:
            training_indep.append(x)

    # training_indep 记录的是所生存的个体编码如【1，0，.....，0，1】

    training_dep = [get_objective_score(r) for r in training_indep]
    
    #规定算法的时间
    cal_time=0
    
    #真实评估个数
    real_cal=0
    #预测准确率
    pre_Accuracy=0
    while(cal_time<3500):
        #求中位数
        #median=get_median(training_dep)
        regressor = RandomForestRegressor(n_estimators=10, random_state=0)
        regressor.fit(training_indep,training_dep)
        #每次迭代重新训练模型
        pre_indep=[]
        pre_dep=[]
        
        
        #这些用来交叉 变异和当割点
        best_indep,best_dep=get_bets_list(training_indep,training_dep)
        
        
        #存储每代最优解
        minx=best_dep[0]
        best_result.append(minx)
        
        
        
        
        
        while(len(pre_indep)<10):  
            print("开始了产生新解")
            #变异一个
            var=random.randrange(len(best_indep))
            new_x=variation_x(best_indep[var])
            
            temp_model_x=np.array(new_x).reshape([1, np.array(new_x).shape[0]])
            pre_new_x=regressor.predict(temp_model_x)
            if(pre_new_x < best_dep[-1]):#大概率是好解
                if new_x not in training_indep:
                    obj_new_x=get_objective_score(new_x)
                    pre_indep.append(new_x)
                    pre_dep.append(obj_new_x)
                    real_cal=real_cal+1
                    if (obj_new_x<best_dep[-1]):
                        pre_Accuracy=pre_Accuracy+1
            #交叉两个
            var_x1=0
            var_x2=0
            while(var_x1==var_x2):
                var_x1=random.randrange(len(best_indep))
                var_x2=random.randrange(len(best_indep))
            new_x1,new_x2=cross_x1_x2(best_indep[var_x1], best_indep[var_x2])
            temp_model_x1=np.array(new_x1).reshape([1, np.array(new_x1).shape[0]])
            
            temp_model_x2=np.array(new_x2).reshape([1, np.array(new_x2).shape[0]])
            
            pre_new_x1=regressor.predict(temp_model_x1)
            pre_new_x2=regressor.predict(temp_model_x2)
            if(pre_new_x1 < best_dep[-1]):#大概率是好解
                if new_x1 not in training_indep:
                    obj_new_x1=get_objective_score(new_x1)
                    pre_indep.append(new_x1)
                    pre_dep.append(obj_new_x1)
                    real_cal=real_cal+1
                    if (obj_new_x1<best_dep[-1]):
                        pre_Accuracy=pre_Accuracy+1
            if(pre_new_x2 < best_dep[-1]):#大概率是好解
                if new_x2 not in training_indep:
                    obj_new_x2=get_objective_score(new_x2)
                    pre_indep.append(new_x2)
                    pre_dep.append(obj_new_x2)
                    real_cal=real_cal+1
                    if (obj_new_x2<best_dep[-1]):
                        pre_Accuracy=pre_Accuracy+1
        for i in pre_indep:
            training_indep.append(i)
        for i in pre_dep:
            training_dep.append(i)
        b=time.time()
        cal_time=b-a
    
    print("***********实验结果**********************")
    print("train_dep",training_dep)
    
    print("真实评估个数",real_cal)
    print("预测正确的个数",pre_Accuracy)
    print("每次迭代的当前最优解",best_result)
    print("****************end********************")
    
    
    
    
    
    
    